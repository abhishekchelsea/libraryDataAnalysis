{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unq_bks = \"/home/aca/Documents/S6_Lab/Projects/libraryDataAnalysis/venv/recomm/rss/unq_bks2.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(data=None, valid_args=None):\n",
    "\n",
    "    if (data is None or valid_args is None):\n",
    "        print(\"No dataframe selected/No arguments passed to combine\")\n",
    "        return\n",
    "\n",
    "    _keys = list(valid_args.keys())\n",
    "\n",
    "    # If you're passing scalar values, you have to pass an index\n",
    "    # https://stackoverflow.com/a/17840195/12616968\n",
    "    _row = pd.DataFrame(valid_args, index=[0])\n",
    "\n",
    "    data = pd.concat([data, _row], axis=0, ignore_index=True)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    sz = data.shape[0]\n",
    "\n",
    "    try:\n",
    "        for i in range(sz):\n",
    "            fea = \"\"\n",
    "            for j in _keys:\n",
    "                fea += data[j][i] + \" \"\n",
    "            features.append(fea)\n",
    "    except:\n",
    "        print(i)\n",
    "    finally:\n",
    "        data[\"combined\"] = features\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar(auth=\"\", pub=\"\", title=\"\", course_code = \"\"):\n",
    "\n",
    "    lst = []\n",
    "\n",
    "    valid_args = {\"author\": \"\",\"title\": \"\", \"publisher\": \"\"}\n",
    "\n",
    "    if (title != \"\"):\n",
    "        valid_args[\"title\"] = title\n",
    "    if (pub != \"\"):\n",
    "        valid_args[\"publisher\"] = pub\n",
    "    if (auth != \"\"):\n",
    "        valid_args[\"author\"] = auth\n",
    "\n",
    "    if (not valid_args):\n",
    "        return \"\"\n",
    "\n",
    "    data = pd.read_csv(path_unq_bks, index_col=0)\n",
    "\n",
    "    if (data is None):\n",
    "        return \"<div class='alert alert-danger'>No data frame selected</div>\"\n",
    "\n",
    "    _temp = combine_features(\n",
    "        data=data[list(valid_args.keys())], valid_args=valid_args)\n",
    "\n",
    "    cm = CountVectorizer().fit_transform(_temp[\"combined\"])\n",
    "\n",
    "    # get cosine similarity mtx\n",
    "    cs = cosine_similarity(cm)\n",
    "\n",
    "    index = cs.shape[0]-1  # index of the added row\n",
    "\n",
    "    a = list(enumerate((cs[index])))\n",
    "\n",
    "    # Sort scores in descending order. More score means higher similarity\n",
    "    sorted_scores = sorted(a, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    count = 0\n",
    "    for i in sorted_scores[1:]:\n",
    "        if (i[1] <= 0.499):\n",
    "            continue\n",
    "        try:\n",
    "            _temp = {}\n",
    "\n",
    "            _temp[\"book_id\"] = int(i[0])\n",
    "            _temp[\"title\"] = data[data.index == i[0]]['title'].values[0]\n",
    "            _temp[\"author\"] = data[data.index == i[0]]['author'].values[0]\n",
    "            _temp[\"publisher\"] = data[data.index ==\n",
    "           ðŸ’¡                           i[0]]['publisher'].values[0]\n",
    "            _temp[\"number_of_books\"] = int(data[data.index ==\n",
    "                                            i[0]]['number_of_books'].values[0])\n",
    "            _temp[\"score\"] = float(i[1])\n",
    "            _temp[\"course_code\"] = course_code\n",
    "\n",
    "            lst.append(_temp)\n",
    "\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count >= 3: # Max recommendation per book title\n",
    "                break\n",
    "\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/home/aca/Documents/S6_Lab/Projects/libraryDataAnalysis/model/feeling_lucky/textbooks\"\n",
    "output_path = \"/home/aca/Documents/S6_Lab/Projects/libraryDataAnalysis/model/feeling_lucky/recommended_bks/\"\n",
    "files = os.listdir(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    _t = {}\n",
    "    with open(os.path.join(input_path, file)) as f:\n",
    "        _ = f.read().strip().split(\"\\n\")\n",
    "        for j in _:\n",
    "            j = j.upper()\n",
    "            _t[j] = search_similar(title = j, course_code = file[:-4])\n",
    "    \n",
    "    with open(os.path.join(output_path, file[:-4] + \".json\"), 'w') as _f:\n",
    "        json.dump(_t, _f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
